<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Improving aspect-based sentiment analysis with Knowledge-aware Dependency Graph Network</title>
      <link href="/2023/04/01/KDGN/"/>
      <url>/2023/04/01/KDGN/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2023 Information Fusion <a href="KDGN.pdf">Paper</a></p></blockquote><hr><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>图结构没有考虑领域知识</p><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><img src="KDGN1.png" width="50%" height="50%"/><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><img src="KDGN2.png" width="50%" height="50%"/>]]></content>
      
      
      <categories>
          
          <category> ABSA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GAT </tag>
            
            <tag> knowledge database </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CORT: A New Baseline for Comparative Opinion Classification by Dual Prompts</title>
      <link href="/2023/04/01/CORT/"/>
      <url>/2023/04/01/CORT/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2022 EMNLP(findings) <a href="CORT.pdf">Paper</a></p></blockquote><hr><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><p>物体比较对顺序非常敏感<br>利用比较的特点设计双通道</p><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><img src="CORT1.png" width="50%" height="50%"/><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><img src="CORT2.png" width="50%" height="50%"/>]]></content>
      
      
      
        <tags>
            
            <tag> prompt learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Learn from structural scope: Improving aspect-level sentiment analysis with hybrid graph convolutional networks</title>
      <link href="/2023/04/01/HGCN/"/>
      <url>/2023/04/01/HGCN/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2023 Neurocomputing <a href="HGCN.pdf">Paper</a></p></blockquote><hr><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><ol><li>span-based模型抽取出的和方面相关的短语不完整 （缺乏语法信息）</li><li>成分句法树可以获取结构完整、连续上下文</li></ol><img src="HGCN0.png" width="50%" height="50%"/><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><img src="HGCN1.png" width="50%" height="50%"/><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><img src="HGCN2.png" width="50%" height="50%"/>]]></content>
      
      
      <categories>
          
          <category> ABSA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> constituency </tag>
            
            <tag> GCN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Aspect Feature Distillation and Enhancement Network for Aspect-based Sentiment Analysis</title>
      <link href="/2023/04/01/AFDEN/"/>
      <url>/2023/04/01/AFDEN/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2022 SIGIR <a href="AFDEN.pdf">Paper</a></p></blockquote><hr><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ol><li>注意力机制关注到方面无关的单词会引入噪声</li><li>交叉熵损失很难利用intra-class和inter-class的隐式信息</li></ol><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><ol><li>消除方面无关单词的干扰 (梯度回传)</li><li>利用相同情感和不同情感之间的信息 (对比学习)</li></ol><img src="AFDEN1.png" width="50%" height="50%"/><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><img src="AFDEN2.png" width="50%" height="50%"/>]]></content>
      
      
      <categories>
          
          <category> ABSA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> contrastive learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Discrete Opinion Tree Induction for Aspect-based Sentiment Analysis</title>
      <link href="/2023/03/25/dotGCN/"/>
      <url>/2023/03/25/dotGCN/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2022 ACL <a href="dotGCN.pdf">Paper</a></p></blockquote><hr><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><ol><li>低资源语言可能没有解析器得到依存树</li><li>现有的依存树没有针对aspect进行优化</li></ol><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>预训练语言模型的注意力分数作为初始化<br>根据注意力分数生成树结构<br>使用强化学习优化生成树的结构</p><img src="dotGCN1.png" width="50%" height="50%"/><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><img src="dotGCN2.png" width="50%" height="50%"/>]]></content>
      
      
      <categories>
          
          <category> ABSA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tree </tag>
            
            <tag> reinforcement learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Contrastive Cross-Channel Data Augmentation Framework for Aspect-Based Sentiment Analysis</title>
      <link href="/2023/03/24/C3DA/"/>
      <url>/2023/03/24/C3DA/</url>
      
        <content type="html"><![CDATA[<h2 id="A-Contrastive-Cross-Channel-Data-Augmentation-Framework-for-Aspect-Based-Sentiment-Analysis"><a href="#A-Contrastive-Cross-Channel-Data-Augmentation-Framework-for-Aspect-Based-Sentiment-Analysis" class="headerlink" title="A Contrastive Cross-Channel Data Augmentation Framework for Aspect-Based Sentiment Analysis"></a>A Contrastive Cross-Channel Data Augmentation Framework for Aspect-Based Sentiment Analysis</h2><blockquote><p>2022 COLING <a href="C3DA.pdf">Paper</a></p></blockquote><hr><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ol><li>数据增强提高预测多方面句子的鲁棒性</li><li>使用预训练语言模型生成</li></ol><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><p>方面和情感双通道 对比学习</p><img src="C3DA1.png" width="50%" height="50%"/><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><img src="C3DA2.png" width="50%" height="50%"/>]]></content>
      
      
      <categories>
          
          <category> ABSA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> contrastive learning </tag>
            
            <tag> data augmentation </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based Sentiment Analysis</title>
      <link href="/2023/03/24/BiSyn-GAT/"/>
      <url>/2023/03/24/BiSyn-GAT/</url>
      
        <content type="html"><![CDATA[<h2 id="BiSyn-GAT-Bi-Syntax-Aware-Graph-Attention-Network-for-Aspect-based-Sentiment-Analysis"><a href="#BiSyn-GAT-Bi-Syntax-Aware-Graph-Attention-Network-for-Aspect-based-Sentiment-Analysis" class="headerlink" title="BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based Sentiment Analysis"></a>BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based Sentiment Analysis</h2><blockquote><p>2022 ACL(Findings) <a href="BiSyn-GAT.pdf">Paper</a></p></blockquote><hr><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ol><li>位置和依存树都不一定能将方面及其对应上下文对齐 <strong>(intra-aspect)</strong></li><li>无法对多个方面的复杂关系建模 <strong>(inter-aspect)</strong></li></ol><h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><ol><li>成分树将复杂句子划分成多个子句，对齐方面及其上下文</li><li>利用依存树的句法信息和成分树的层次结构，对方面上下文和方面之间的关系进行建模</li></ol><img src="BiSyn-GAT1.png" width="50%" height="50%"/><h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><img src="BiSyn-GAT2.png" width="50%" height="50%"/>]]></content>
      
      
      <categories>
          
          <category> ABSA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> constituency </tag>
            
            <tag> dependency </tag>
            
            <tag> GAT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention and Lexicon Regularized LSTM for Aspect-based Sentiment Analysis</title>
      <link href="/2023/03/19/ATLX/"/>
      <url>/2023/03/19/ATLX/</url>
      
        <content type="html"><![CDATA[<blockquote><p>2022 ACL(Findings) <a href="ATLX.pdf">Paper</a></p></blockquote><hr><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><ol><li>端到端深度神经网络在训练数据少时缺乏灵活性，注意力机制可能会过度关注句子的特定部分，而忽略了为判断极性提供关键信息的位置 <strong>(over-attention)</strong></li><li>作者提出利用词典信息这一简单有效方法，使模型灵活性和鲁棒性更强，另外，作者对注意力向量正则化，使模型获得对句子不同部分有更多的关注点 <strong>(lexicon+regularize)</strong></li></ol><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><ol><li>Lexicon feature: 合并MPQA, Opinion Lexicon, Opener和Vader四个词典，SentiWordNet因引入噪音而被移除。将每个词在不同词典的最大极性分数拼接，作为该词的极性分数向量 例如: adorable [1.0, 1.0, 1.0, 0.55] MPQA(1.0), Opener(1.0), Opinion Lexicon(1.0) and Vader(0.55)</li><li>Attention Regularization: 为了减小注意力过拟合，作者在损失函数加入对注意力分数的正则化R(α)，提出了两种计算方法：标准差和负信息熵</li></ol><img src="ATLX1.png" width="50%" height="50%"/><h1 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h1><img src="ATLX2.png" width="50%" height="50%"/>]]></content>
      
      
      <categories>
          
          <category> ABSA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> sentiment lexicon </tag>
            
            <tag> attention </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
